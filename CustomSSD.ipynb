{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Ivy7qFe2BwbU"
   },
   "source": [
    "## Programming Environment"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "id": "oOEpRvCPcj5-"
   },
   "outputs": [],
   "source": [
    "# 3rd Party\n",
    "import tensorflow as tf\n",
    "import numpy as np\n",
    "from object_detection.metrics.coco_tools import COCOWrapper,COCOEvalWrapper\n",
    "# Python STL\n",
    "from typing import List,Tuple,Dict\n",
    "import os\n",
    "import pdb\n",
    "import json"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "id": "NXexdkUPpB6E"
   },
   "outputs": [],
   "source": [
    "from preprocess.construct_dicts import construct_dicts, construct_desired_ids\n",
    "from preprocess.preprocess import preprocess_train_images, preprocess_validation_images, preprocess_test_images, \\\n",
    "  construct_category_index, get_unsliced_images_np, calculate_label_id_offsets, map_category_ids_to_index\n",
    "from retrain.retrain import retrain\n",
    "from utils.load_data import get_annotations\n",
    "from utils.plot import visualize_image_set\n",
    "from evaluate.detect import run_inference\n",
    "from evaluate.postprocess import restore_image_detections, run_nms\n",
    "from evaluate.eval import write_window_validation_file, write_window_results, evaluate\n",
    "from retrain.retrain import convert_to_tensors\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "id": "1xjBn9Gtxv7A"
   },
   "outputs": [],
   "source": [
    "from ssd.ssd512_vgg16 import SSD512_VGG16"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "id": "M5gXJz1NwbAr"
   },
   "outputs": [],
   "source": [
    "log_dir = \"./tb\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "W2vsumHF59T8"
   },
   "source": [
    "## Training Setup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 34
    },
    "id": "uXDnxOaq3CUW",
    "outputId": "304cc44b-1ace-4661-b485-799999357756"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{2: {'id': 2, 'name': 'baseball-diamond'}, 4: {'id': 4, 'name': 'ground-track-field'}, 8: {'id': 8, 'name': 'tennis-court'}, 11: {'id': 11, 'name': 'soccer-ball-field'}}\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "data_path = \"./dota_sports_data\"\n",
    "# set image path info\n",
    "train_image_dir = data_path + '/train/images/' \n",
    "train_annotations_dir = data_path + '/annotations/train.json'\n",
    "# open annotation information\n",
    "train_annotations = get_annotations(train_annotations_dir)\n",
    "desired_categories = {'tennis-court','soccer-ball-field','ground-track-field','baseball-diamond'}\n",
    "desired_ids = construct_desired_ids(desired_categories, train_annotations['categories'])\n",
    "# construct dictionaries containing info about images\n",
    "(train_images_dict, train_file_name_dict) = construct_dicts(train_annotations)\n",
    "# create category index in the correct format for retraining and detection\n",
    "category_index = construct_category_index(train_annotations, desired_categories)\n",
    "label_id_offsets = calculate_label_id_offsets(category_index)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "id": "Fguk__RvNsHV"
   },
   "outputs": [],
   "source": [
    "# set windowing information (size of window and stride); these values taken from DOTA paper\n",
    "win_height = 1024\n",
    "win_width  = 1024\n",
    "win_stride_vert  = 512\n",
    "win_stride_horiz = 512\n",
    "win_set = (win_height, win_width, win_stride_vert, win_stride_horiz) # windowing information"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "id": "L4CossbiGYI5"
   },
   "outputs": [],
   "source": [
    "(train_images_np, gt_boxes, gt_classes) = preprocess_train_images(\n",
    "  train_images_dict, train_file_name_dict, train_image_dir,train_annotations,\n",
    "  category_index, win_set,verbose = False)\n",
    "\n",
    "gt_classes = map_category_ids_to_index(label_id_offsets, gt_classes)\n",
    "(train_image_tensors, gt_box_tensors, gt_classes_one_hot_tensors) = convert_to_tensors(\n",
    "        train_images_np, gt_boxes, gt_classes, label_id_offsets, len(category_index))                                                     "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "id": "34ENDKjVVejk"
   },
   "outputs": [],
   "source": [
    "valid_annotations_dir  = data_path + '/annotations/validation.json'\n",
    "\n",
    "valid_image_dir  = data_path + '/validation/images/'\n",
    "valid_annotations  = get_annotations(valid_annotations_dir)\n",
    "(valid_images_dict, valid_file_name_dict)   = construct_dicts(valid_annotations)\n",
    "(valid_images_np, valid_gt_boxes, valid_gt_classes, valid_images_dict, valid_no_annotation_ids) = preprocess_validation_images(\n",
    "  valid_images_dict, valid_file_name_dict, valid_image_dir, valid_annotations,\n",
    "  category_index, win_set, verbose=False)\n",
    "(valid_image_tensors, valid_box_tensors, valid_class_tensors) = convert_to_tensors(\n",
    "    valid_images_np, valid_gt_boxes, valid_gt_classes, label_id_offsets, len(category_index)\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "id": "h2XRhy_Dk0pC"
   },
   "outputs": [],
   "source": [
    "from collections import namedtuple\n",
    "ObjDataset = namedtuple(\"ObjDataset\", [\"images\", \"boxes\", \"classes\"])\n",
    "train_dataset = ObjDataset(train_image_tensors, gt_box_tensors, gt_classes_one_hot_tensors)\n",
    "valid_dataset = ObjDataset(\n",
    "                            [t for (i, t) in enumerate(valid_image_tensors) if i not in valid_no_annotation_ids],\n",
    "                            [t for (i, t) in enumerate(valid_box_tensors) if i not in valid_no_annotation_ids],\n",
    "                            [t for (i, t) in enumerate(valid_class_tensors) if i not in valid_no_annotation_ids]\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "id": "7S64aMwqNx18"
   },
   "outputs": [],
   "source": [
    "def coco_eval(data_path, annotations, images_np, images_dict, desired_ids, label_id_offsets, model):\n",
    "  results_path = os.path.join(data_path, \"annotations\", \"evaluation\", \"window_results.json\")\n",
    "  labels_path = os.path.join(data_path, \"annotations\", \"validation_window.json\")\n",
    "\n",
    "  test_images_dict, predicted_boxes, predicted_classes, predicted_scores = run_inference(images_np, images_dict, label_id_offsets, model)\n",
    "  write_window_validation_file(data_path, annotations, images_dict)\n",
    "  write_window_results(results_path, images_dict, min_threshold=.01)\n",
    "\n",
    "  with open(labels_path, \"r\") as r: cocoGt = COCOWrapper(json.load(r))\n",
    "  cocoDt = cocoGt.loadRes(results_path)\n",
    "  cocoEval = COCOEvalWrapper(cocoGt, cocoDt, iou_type=\"bbox\", agnostic_mode=True)\n",
    "  cocoEval.params.catIds = list(desired_ids) # set category ids we want to evaluate on\n",
    "  metrics = cocoEval.ComputeMetrics()\n",
    "  return metrics \n",
    "\n",
    "class COCOEvalCallback(tf.keras.callbacks.Callback):\n",
    "  def __init__(self, coco_eval_kwargs, log_dir):\n",
    "    super(COCOEvalCallback, self).__init__()\n",
    "    self._coco_eval_kwargs = coco_eval_kwargs\n",
    "    os.makedirs(log_dir, exist_ok=True)\n",
    "    self._writer = tf.summary.create_file_writer(log_dir)\n",
    "    self._metrics = [\n",
    "                     \"Precision/mAP\",\n",
    "                     \"Precision/mAP@.50IOU\",\n",
    "                     \"Precision/mAP@.75IOU\",\n",
    "                     \"Recall/AR@100\"\n",
    "    ]\n",
    "\n",
    "  def on_epoch_begin(self, epoch, logs = None):\n",
    "    pass\n",
    "\n",
    "  def on_epoch_end(self, epoch, logs = None):\n",
    "    metrics_dict = coco_eval(**self._coco_eval_kwargs)\n",
    "    with self._writer.as_default():\n",
    "      for m in self._metrics:\n",
    "        tf.summary.scalar(m, metrics_dict[0][m], step=epoch)\n",
    "    self._writer.flush()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "id": "xUC6SBA75iTE"
   },
   "outputs": [],
   "source": [
    "class SummaryScalarCallback(tf.keras.callbacks.Callback):\n",
    "  def __init__(self, log_dir):\n",
    "    super(SummaryScalarCallback, self).__init__()\n",
    "    os.makedirs(log_dir, exist_ok=True)\n",
    "    self._writer = tf.summary.create_file_writer(log_dir)\n",
    "  def on_epoch_begin(self, epoch, logs = None):\n",
    "    pass\n",
    "  def on_epoch_end(self, epoch, logs = None):\n",
    "    if logs is None: return\n",
    "    with self._writer.as_default():\n",
    "      for (k,v) in logs.items():\n",
    "        tf.summary.scalar(k, v, step=epoch)\n",
    "    self._writer.flush()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "id": "mNE1CzauACzQ"
   },
   "outputs": [],
   "source": [
    "def save_checkpoint(ckpt: tf.train.Checkpoint, ckpt_path: str):\n",
    "  dir_name = os.path.dirname(ckpt_path)\n",
    "  os.makedirs(dir_name, exist_ok=True)\n",
    "  ckpt.save(ckpt_path)\n",
    "\n",
    "class ModelCheckpointCallback(tf.keras.callbacks.Callback):\n",
    "  def __init__(self, ckpt: tf.train.Checkpoint, ckpt_path: str):\n",
    "    super(ModelCheckpointCallback, self).__init__()\n",
    "    self._ckpt = ckpt\n",
    "    self._ckpt_path = ckpt_path\n",
    "  def on_epoch_begin(self, epoch, logs = None):\n",
    "    pass\n",
    "  def on_epoch_end(self, epoch, logs = None):\n",
    "    save_checkpoint(self._ckpt, self._ckpt_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "id": "aPHtkUT7QYol"
   },
   "outputs": [],
   "source": [
    "import pdb\n",
    "\n",
    "def shuffle_and_batch(dataset: tf.data.Dataset, batch_size=8, random_seed=0) -> tf.data.Dataset:\n",
    "  dataset = dataset.shuffle(buffer_size=batch_size*4,seed=random_seed)\n",
    "  dataset = dataset.batch(batch_size)\n",
    "  return dataset\n",
    "\n",
    "\n",
    "def get_valid_loss_fn(valid_dataset: ObjDataset, model, batch_size=8):\n",
    "  if not valid_dataset: return lambda: 0.\n",
    "  (image_tensors, box_tensors, class_tensors) = valid_dataset\n",
    "  image_tensors = tf.squeeze( tf.stack([model.preprocess(t)[0] for t in image_tensors], axis=0) )\n",
    "  raw_index_dataset = tf.data.Dataset.from_generator(lambda: range(len(image_tensors)), output_types=tf.int32)\n",
    "  valid_loss = tf.keras.metrics.Mean(\"valid_loss\", dtype=tf.float32)\n",
    "  def f():\n",
    "    index_dataset = raw_index_dataset.batch(batch_size)\n",
    "    for indices in index_dataset:\n",
    "      model.provide_groundtruth(\n",
    "          [box_tensors[i] for i in indices],\n",
    "          [class_tensors[i] for i in indices]\n",
    "      )\n",
    "      prediction_dict = model.predict(tf.gather(image_tensors, indices), None)\n",
    "      loss_val = model.loss(prediction_dict)[\"WeightedTotal\"]\n",
    "      valid_loss(loss_val)\n",
    "    result = valid_loss.result()\n",
    "    valid_loss.reset_states()\n",
    "    return result\n",
    "  return f\n",
    "\n",
    "def train_model(model, optimizer, train_dataset,\n",
    "                batch_size : int = 8,\n",
    "                num_epochs : int = 1,\n",
    "                epoch_start : int = 1,\n",
    "                valid_dataset = None,\n",
    "                callbacks : List[tf.keras.callbacks.Callback] = []):\n",
    "\n",
    "\n",
    "  to_fine_tune = [v for v in model.trainable_variables]\n",
    "  valid_loss_fn = get_valid_loss_fn(valid_dataset, model, batch_size=batch_size)\n",
    "  (image_tensors, gt_box_tensors, gt_classes_one_hot_tensors) = train_dataset\n",
    "\n",
    "  image_tensors = tf.squeeze( tf.stack([model.preprocess(t)[0] for t in image_tensors], axis=0) )\n",
    "\n",
    "  train_loc_loss = tf.keras.metrics.Mean(\"train_loc_loss\", dtype=tf.float32)\n",
    "  train_conf_loss = tf.keras.metrics.Mean(\"train_conf_loss\", dtype=tf.float32)\n",
    "\n",
    "  raw_dataset = tf.data.Dataset.from_generator(lambda: range(len(image_tensors)), output_types=tf.int32)\n",
    "  for i_epoch in range(epoch_start, epoch_start + num_epochs):\n",
    "    for c in callbacks: c.on_epoch_begin(i_epoch)\n",
    "    dataset = shuffle_and_batch(raw_dataset, batch_size=batch_size, random_seed=i_epoch)\n",
    "    for (i_batch, indices) in enumerate(dataset):\n",
    "      for c in callbacks: c.on_train_batch_begin(i_batch)\n",
    "      batch_images = tf.gather(image_tensors, indices)\n",
    "      model.provide_groundtruth(\n",
    "          [gt_box_tensors[i] for i in indices],\n",
    "          [gt_classes_one_hot_tensors[i] for i in indices]\n",
    "      )\n",
    "      with tf.GradientTape() as tape:\n",
    "        prediction_dict = model.predict(batch_images, None)\n",
    "        loss_dict = model.loss(prediction_dict)\n",
    "      gradients = tape.gradient(loss_dict[\"WeightedTotal\"], to_fine_tune)\n",
    "      optimizer.apply_gradients( zip(gradients, to_fine_tune) )\n",
    "      train_loc_loss(loss_dict[\"Localization\"])\n",
    "      train_conf_loss(loss_dict[\"Confidence\"])\n",
    "      for c in callbacks: c.on_train_batch_end(i_batch, logs = {})\n",
    "#       break\n",
    "\n",
    "    losses_dict = {\n",
    "        \"Loss/Train/Localization\": train_loc_loss.result(),\n",
    "        \"Loss/Train/Confidence\": train_conf_loss.result(),\n",
    "        \"Loss/Validation\": valid_loss_fn()\n",
    "    }\n",
    "    for c in callbacks: c.on_epoch_end(i_epoch, losses_dict)\n",
    "    train_loc_loss.reset_states()\n",
    "    train_conf_loss.reset_states()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "id": "JvELKhuZSQba"
   },
   "outputs": [],
   "source": [
    "checkpoints_root = \"./checkpoints\"\n",
    "vars_checkpoint_dir = os.path.join(checkpoints_root, \"ssd-variables\")\n",
    "opt_checkpoint_dir = os.path.join(checkpoints_root, \"ssd-optimizer\")\n",
    "vars_checkpoint_path = os.path.join(vars_checkpoint_dir, \"ckpt\")\n",
    "opt_checkpoint_path = os.path.join(opt_checkpoint_dir, \"ckpt\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "id": "YAF9NIRI-HjX"
   },
   "outputs": [],
   "source": [
    "# optimizer = tf.keras.optimizers.SGD(learning_rate=1e-6, momentum=0.9)\n",
    "optimizer = tf.keras.optimizers.Adam(learning_rate=1e-6)\n",
    "# optimizer = tf.keras.optimizers.SGD(learning_rate=1e-6, momentum=0.9)\n",
    "optimizer_checkpoint = tf.train.Checkpoint(optimizer=optimizer)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "id": "6rKFRjkKE9K6"
   },
   "outputs": [],
   "source": [
    "load_old_model = False\n",
    "if load_old_model:\n",
    "  model = SSD512_VGG16.from_checkpoint(len(category_index), tf.train.latest_checkpoint(vars_checkpoint_dir))\n",
    "else:\n",
    "  weights_path = \"/data/pretrained_models/vgg16_weights_tf_dim_ordering_tf_kernels_notop.h5\"\n",
    "  model = SSD512_VGG16.from_scratch(len(category_index), weights_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "id": "6rKFRjkKE9K6"
   },
   "outputs": [],
   "source": [
    "load_old_optimizer = False\n",
    "if load_old_optimizer:\n",
    "  optimizer_checkpoint.restore( tf.train.latest_checkpoint(opt_checkpoint_dir) )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {
    "id": "ONW0brAY1g4C"
   },
   "outputs": [],
   "source": [
    "import os\n",
    "callbacks = []\n",
    "\n",
    "coco_eval_callback = COCOEvalCallback({\n",
    "    \"model\": model, \"images_np\": valid_images_np, \"images_dict\": valid_images_dict,\n",
    "    \"desired_ids\": desired_ids, \"label_id_offsets\": label_id_offsets, \"annotations\": valid_annotations,\n",
    "    \"data_path\": data_path\n",
    "},log_dir=os.path.join(log_dir, \"coco\"))\n",
    "callbacks.append(coco_eval_callback)\n",
    "\n",
    "\n",
    "summary_callback = SummaryScalarCallback(log_dir=os.path.join(log_dir, \"metrics\"))\n",
    "callbacks.append(summary_callback)\n",
    "\n",
    "model_save_callback = ModelCheckpointCallback(model.checkpoint, vars_checkpoint_path)\n",
    "callbacks.append(model_save_callback)\n",
    "\n",
    "opt_save_callback = ModelCheckpointCallback(optimizer_checkpoint, opt_checkpoint_path)\n",
    "callbacks.append(opt_save_callback)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 1000
    },
    "id": "xjbY1_2BdKAr",
    "outputId": "b11057ba-fa23-4b21-b4a5-c60d2d54fb1e"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "creating index...\n",
      "index created!\n",
      "Loading and preparing results...\n",
      "DONE (t=0.06s)\n",
      "creating index...\n",
      "index created!\n",
      "Running per image evaluation...\n",
      "Evaluate annotation type *bbox*\n",
      "DONE (t=0.42s).\n",
      "Accumulating evaluation results...\n",
      "DONE (t=0.04s).\n",
      " Average Precision  (AP) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.000\n",
      " Average Precision  (AP) @[ IoU=0.50      | area=   all | maxDets=100 ] = 0.000\n",
      " Average Precision  (AP) @[ IoU=0.75      | area=   all | maxDets=100 ] = 0.000\n",
      " Average Precision  (AP) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = -1.000\n",
      " Average Precision  (AP) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = -1.000\n",
      " Average Precision  (AP) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.000\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=  1 ] = 0.000\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets= 10 ] = 0.001\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.019\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = -1.000\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = -1.000\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.019\n"
     ]
    }
   ],
   "source": [
    "train_model(model,optimizer,train_dataset,\n",
    "            valid_dataset=valid_dataset,\n",
    "            batch_size=4, num_epochs=30, epoch_start=50, callbacks=callbacks)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "mFeV6AbKE57U"
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "collapsed_sections": [],
   "name": "CustomSSD.ipynb",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "dota_ssd",
   "language": "python",
   "name": "dota_ssd"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
